{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Importing required Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define some constant needed throughout the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 4\n",
    "EPOCHS = 1000\n",
    "PATIENCE = 5\n",
    "TRAIN_PATH= '/floyd/input/tomato_disease_v3_mix/Train'\n",
    "VALID_PATH = '/floyd/input/tomato_disease_v3_mix/Validation'\n",
    "TEST_PATH = '/floyd/input/tomato_disease_v3_mix/test filtered'\n",
    "MODEL_CHECK_WEIGHT_NAME = 'resnet_tomato_v3_chk.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Define model to be used**\n",
    "we freeze the pre trained resnet model weight, and add few layer on top of it to utilize our custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n",
    "model = ResNet50(input_shape=(224,224,3),include_top=False, weights=None, pooling='avg')\n",
    "K.set_learning_phase(1)\n",
    "x = model.output\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(N_CLASSES, activation='softmax', name='custom_output')(x)\n",
    "custom_resnet = Model(inputs=model.input, outputs = output)\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "custom_resnet.compile(Adam(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#custom_resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Load dataset to be used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6750 images belonging to 4 classes.\n",
      "Found 1198 images belonging to 4 classes.\n",
      "Found 114 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "traingen = datagen.flow_from_directory(TRAIN_PATH, target_size=(224,224), batch_size=32, class_mode='categorical')\n",
    "validgen = datagen.flow_from_directory(VALID_PATH, target_size=(224,224), batch_size=32, class_mode='categorical')\n",
    "testgen = datagen.flow_from_directory(TEST_PATH,target_size=(224,224), batch_size=32, class_mode='categorical', shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Train Model**\n",
    "we use ModelCheckpoint to save the best model based on validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 213s - loss: 11.1231 - acc: 0.3074 - val_loss: 10.8844 - val_acc: 0.3247\n",
      "Epoch 2/1000\n",
      " - 193s - loss: 11.0411 - acc: 0.3150 - val_loss: 10.9382 - val_acc: 0.3214\n",
      "Epoch 3/1000\n",
      " - 193s - loss: 11.0395 - acc: 0.3151 - val_loss: 10.6557 - val_acc: 0.3389\n",
      "Epoch 4/1000\n",
      " - 192s - loss: 1.6220 - acc: 0.3891 - val_loss: 1.3214 - val_acc: 0.3548\n",
      "Epoch 5/1000\n",
      " - 192s - loss: 1.2930 - acc: 0.3877 - val_loss: 1.3256 - val_acc: 0.3548\n",
      "Epoch 6/1000\n",
      " - 192s - loss: 1.2892 - acc: 0.3903 - val_loss: 1.2930 - val_acc: 0.3548\n",
      "Epoch 7/1000\n",
      " - 192s - loss: 1.2883 - acc: 0.3978 - val_loss: 1.2898 - val_acc: 0.3548\n",
      "Epoch 8/1000\n",
      " - 192s - loss: 1.2883 - acc: 0.3997 - val_loss: 1.2832 - val_acc: 0.3548\n",
      "Epoch 9/1000\n",
      " - 192s - loss: 1.2865 - acc: 0.3982 - val_loss: 1.2847 - val_acc: 0.3548\n",
      "Epoch 10/1000\n",
      " - 192s - loss: 1.2894 - acc: 0.3973 - val_loss: 1.2943 - val_acc: 0.3548\n",
      "Epoch 11/1000\n",
      " - 192s - loss: 1.2870 - acc: 0.3973 - val_loss: 1.2981 - val_acc: 0.3548\n",
      "Epoch 12/1000\n",
      " - 192s - loss: 1.2868 - acc: 0.4014 - val_loss: 1.2851 - val_acc: 0.3548\n",
      "Epoch 13/1000\n"
     ]
    }
   ],
   "source": [
    "es_callback = EarlyStopping(monitor='val_acc', patience=PATIENCE, mode='max')\n",
    "mc_callback = ModelCheckpoint(filepath=MODEL_CHECK_WEIGHT_NAME, monitor='val_acc', save_best_only=True, mode='max')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, mode='min', verbose = 1)\n",
    "train_history = custom_resnet.fit_generator(traingen, steps_per_epoch=len(traingen), epochs= EPOCHS, validation_data=validgen, validation_steps=len(validgen), verbose=2, callbacks=[reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(221)\n",
    "plt.plot(train_history.history['acc'])\n",
    "plt.plot(train_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train accuracy','validation accuracy'])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Load Last Checkpoint Weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_resnet.load_weights(MODEL_CHECK_WEIGHT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print validation confusion matrix, classification report, and accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 920ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  4,  9,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  5,  9,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  6,  8,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  4, 10,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3, 10],\n",
       "       [ 9,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 4, 11,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  4,  9,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  3,  9,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  6,  8,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = custom_resnet.predict_generator(testgen, steps=len(testgen), verbose=1)\n",
    "test_labels = testgen.classes\n",
    "confusion_matrix(test_labels, predict.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                           precision    recall  f1-score   support\\n\\n              bald_uakari       0.00      0.00      0.00        13\\nblack_headed_night_monkey       0.00      0.00      0.00        14\\n   common_squirrel_monkey       0.00      0.00      0.00        14\\n         japanese_macaque       0.00      0.00      0.00        15\\n           mantled_howler       0.00      0.00      0.00        13\\n           nilgiri_langur       0.00      0.00      0.00        13\\n             patas_monkey       0.00      0.00      0.00        15\\n           pygmy_marmoset       0.00      0.00      0.00        13\\n         silvery_marmoset       0.00      0.00      0.00        13\\n    white_headed_capuchin       0.00      0.00      0.00        14\\n\\n                micro avg       0.00      0.00      0.00       137\\n                macro avg       0.00      0.00      0.00       137\\n             weighted avg       0.00      0.00      0.00       137\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_labels = list(testgen.class_indices.keys())\n",
    "classification_report(test_labels, predict.argmax(axis=1), target_names=cr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,predict.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
